# 建立 Claude Skill 以管理專案級 Obsidian 資料庫的設計與實作研究報告

## 執行摘要

本報告提出一個以「Claude Skill + 本地索引服務」為核心的專案級 Obsidian 資料庫管理方案：Skill 負責把「如何做」與「何時做」固化為可重複使用的工作流程（含漸進式披露與會話治理），而本地索引服務（建議作為 MCP server）負責把 Obsidian Vault 的 Markdown 檔案轉為可查詢的結構化索引（BM25/FTS5）與向量索引（sqlite-vec），並提供可控的讀寫 API 與審計紀錄。此分層可同時滿足：大量檔案與頻繁更新下的效能、上下文節制（progressive disclosure）、以及安全邊界清楚（權限與加密）。citeturn11view0turn4view0turn4view1turn1view3

在「Skill 設計」面，官方（Agent Skills）建議採三層漸進式披露：YAML frontmatter 永遠載入、SKILL.md 主體在相關時載入、其餘檔案在按需時載入；並要求固定的資料夾/檔名結構（SKILL.md、scripts/、references/、assets/），以及以 description 文字作為自動觸發的關鍵之一。此結構直接對應你提出的「避免一次塞滿 context」與「可擴充的專案級知識」需求。citeturn11view0turn11view4turn12view3

在「檢索引擎」面，本報告建議用 SQLite FTS5 實作 BM25（詞彙檢索），其內建 `bm25()` 並支援欄位權重（可把標題/屬性/Heading 給更高權重），亦支援以 `rank` 以較低成本排序；同時以 sqlite-vec 的 `vec0` 虛擬表保存 chunk 向量並以 `MATCH` 進行 KNN 查詢回傳距離。混合檢索預設權重採 BM25 0.7 + 向量 0.3，並提供「動態權重調整策略」：依查詢型態、詞彙命中強度與候選集合一致性自動微調。citeturn13view0turn10view0turn1view0turn13view2

在「同步與頻繁更新」面，本報告主張以「檔案事件 → 去抖動批次更新 → 單次交易原子提交」為主，並採 WAL 模式提升讀寫併發（讀者不阻擋寫者、寫者多數情境不阻擋讀者），但仍要接受 SQLite 本質上「單寫者」的限制與 `SQLITE_BUSY` 的邊界情形，因此需搭配 busy timeout、短交易、寫入序列化佇列與可重建策略（FTS5 `rebuild`）。citeturn19view0turn19view1turn13view3

在「安全」面，重點風險在於：① MCP server 的檔案讀寫能力可能被間接提示注入放大；② SQLite loadable extension 需要啟用 extension loading（預設關閉）且若啟用不當可能被 SQL injection 濫用。因此建議以「最小權限」設計 MCP 工具、強制使用 allowlist 路徑、寫入前做雜湊比對與人工核准（MCP/Claude Desktop 的工具核准機制），並依 SQLite 官方建議以 `SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION` 僅開 C-API、避免啟用 SQL `load_extension()`；資料加密可考慮 SQLite SEE（官方加密延伸）或 SQLCipher（由 entity["company","Zetetic","sqlcipher vendor"] 提供）。citeturn4view1turn16view2turn16view3turn16view4turn16view5turn16view0

## 需求、權限與錯誤模型

### 目標與非目標

目標是建立一個可被 Claude 自動載入的 Skill（以 Agent Skills 規格包裝），用於「專案級」Obsidian Vault 管理：支援跨專案檢索、跨檔案結構化查詢（屬性/Heading/任務）、變更紀錄、對話狀態保存與壓縮，以及頻繁更新下的增量索引。Skill 的角色是「工作流程與治理」，而不是把所有資料直接塞進模型上下文；資料存取與索引運算應交給 MCP server 或本地服務，並以工具呼叫的方式按需取回。citeturn11view0turn18view0turn4view0

非目標（建議明確寫在 SKILL.md 的 Scope 之中）包括：在未授權的路徑做遞迴掃描、直接修改 `.obsidian/` 內的設定檔、以及在未建立審計紀錄的狀況下批量覆寫大量筆記。Obsidian 的 Vault API 在 plugin 內預設只允許存取「App 可見」檔案，隱藏資料夾（例如 `.obsidian`）需用 Adapter API 才能存取；若你的方案要覆蓋此範圍，必須在權限模型上更謹慎。citeturn1view1

### 具體功能需求清單

以下以「輸入/輸出」「觸發條件」「權限」「錯誤處理」四個面向，整理你的必備功能（建議最終落在 `references/requirements.md`，而 SKILL.md 只保留最小可用摘要，以符合大上下文最佳實務）。citeturn12view3

功能面向可分為六類：

1) **Vault 掃描與結構映射**
- 輸入：Vault 根目錄（或 Obsidian Vault 名稱）、專案規則（資料夾模式、frontmatter 欄位、命名規範）。
- 輸出：`path_map`（路徑→用途→更新頻率→權限等級）、`doc_catalog`（檔案清單、hash、mtime、大小、project_id）。
- 觸發：首次安裝、手動 `/index.build`、檔案事件累積達門檻、或檢索出現「索引缺失」。
- 權限：Read-only 可完成；若要補寫 frontmatter（例如補 `id`、`updated`）則需 Write 權限。
- 錯誤：路徑不可讀、符號連結跳脫 Vault、檔名衝突、編碼錯誤（UTF-8 以外）。

2) **索引建立與更新（FTS5 + sqlite-vec）**
- 輸入：Markdown 文字、切 chunk 規則、embedding 模型/服務、BM25 欄位權重。
- 輸出：SQLite 檔（metadata/FTS/vector tables）、build/更新統計（耗時、chunk 數、失敗數）。
- 觸發：新增/修改/刪除/更名、或定期健康檢查。
- 權限：需寫入索引 DB；不一定要寫回 Vault。
- 錯誤：`SQLITE_BUSY`、FTS/內容表不一致（需 rebuild）、embedding 失敗或速率限制。citeturn13view3turn19view0turn19view1

3) **混合檢索與排序（BM25 0.7 + Vec 0.3）**
- 輸入：使用者 query（可含 filters）、top_k、權重設定。
- 輸出：候選清單（含 score 分解、snippet、來源路徑）、可展開的 chunk 內容。
- 觸發：一般問答、`/search ...`、或在其它流程中「需要找資料」。
- 權限：通常 read-only；若包含「根據結果產生/修正筆記」才需要 write。
- 錯誤：索引未就緒（fallback 到純 BM25 或純向量）、查詢語法錯誤、超時。

4) **漸進式披露（Context 節制）**
- 輸入：候選清單、預算（token/字數）、使用者意圖（概覽/深讀/比對/產出）。
- 輸出：分層回應（概覽 → 摘要 → 精選引用 → 全文按需抓取）。
- 觸發：每一次檢索回傳；或專案狀態更新時。
- 權限：read-only。
- 錯誤：引用段落找不到（chunk offset 漂移）、內容過大需切分。

5) **會話自動保存/壓縮與變更紀錄**
- 輸入：對話 turn、工具呼叫結果、變更摘要。
- 輸出：`session_state`、rolling summary、`CHANGELOG.md`/`audit_log` 表。
- 觸發：每次寫操作後、turn 數/估算 token 超過門檻、或手動 `/session.compact`。
- 權限：寫入索引 DB 或 Vault 某個指定資料夾。
- 錯誤：寫入衝突、摘要失敗、版本號不一致。

6) **頻繁更新處理**
- 輸入：檔案事件流、批次大小、去抖動時間。
- 輸出：增量更新交易、延遲統計、失敗重試佇列。
- 觸發：檔案監聽事件（modify/create/delete/rename）。
- 權限：read/write 索引 DB。
- 錯誤：事件風暴、併發鎖、WAL checkpoint 壓力。citeturn19view0turn19view1

### MCP 工具介面設計建議

你要的「專案級管理」通常需要本地檔案與資料庫能力；MCP 的定位正是以標準化方式提供「受控的本地資源存取」。MCP server 可在本機執行並把工具暴露給 Claude Desktop；此類工具一般需要「每次動作的明確核准」，以確保使用者保持控制權。citeturn4view1turn4view0

下表是建議的 MCP 工具清單（以“最小可用”為基準；擴充項可放到 `references/mcp_tools.md`）：

| 工具名稱（建議） | 主要用途 | 典型輸入 | 典型輸出 | 權限等級（例） | 主要錯誤類型（例） |
|---|---|---|---|---|---|
| `vault.scan` | 建立/更新路徑映射與檔案 catalog | `vault_root`, `ruleset_id` | 檔案列表、統計 | Read | 路徑不可讀、Vault 未設定 |
| `index.build` | 全量建索引（首次/重建） | `mode=full`, `chunk_policy` | 進度、build_id | Write(Index) | 資源不足、超時 |
| `index.update` | 增量更新（批次） | `changed_paths[]` | 更新統計 | Write(Index) | `SQLITE_BUSY`、檔案消失 |
| `search.lexical` | FTS5 BM25 查詢 | `query`, `filters`, `top_k` | rowids、bm25/rank、snippet | Read | 語法錯、索引未就緒 |
| `search.vector` | sqlite-vec KNN 查詢 | `embedding`, `top_k` | rowids、distance | Read | extension 未載入、維度不符 |
| `search.hybrid` | 統一混合檢索 | `query`, `weights`, `top_k` | 合併排序結果 | Read | 任一子查詢失敗 |
| `doc.get_chunks` | 漸進式披露：只取必要片段 | `chunk_ids[]` 或 `path+range` | chunk 文字、來源定位 | Read | chunk 漂移、檔案不存在 |
| `doc.apply_patch` | 受控寫入（少量 patch） | `path`, `expected_hash`, `patch` | 新 hash、變更紀錄 | Write(Vault) | 衝突、拒絕寫入 |
| `session.save` | 保存會話 state | `session_id`, `delta` | ack、版本 | Write(Index/Vault) | 版本衝突 |
| `session.compact` | 壓縮會話（rolling summary） | `session_id`, `policy` | summary、可追溯引用 | Write(Index/Vault) | 壓縮失敗 |

若你走「Claude API（Messages API）+ 自建 MCP client」路線，需要注意：MCP 工具定義中的 `inputSchema` 要轉成 Claude tool 需要的 `input_schema`；且 Claude 的 server tool loop 有預設迭代上限，超過會以 `stop_reason="pause_turn"` 暫停，需要你把回應再送回去續跑。citeturn1view2

### 錯誤模型與回復策略

建議把錯誤分成三層（並在 SKILL.md 明確規定回應格式，以利自動化與測試）：

- **可重試（Retryable）**：例如 WAL 模式下仍可能遇到 `SQLITE_BUSY`，應支援退避重試、縮短交易、或把寫入排隊序列化。citeturn19view0turn19view1  
- **可降級（Degradable）**：例如向量索引不可用時退回純 BM25；或詞彙索引損壞時退回向量＋路徑 filter。  
- **需人工介入（Manual）**：例如 `expected_hash` 不符造成寫入衝突；或安全策略拒絕存取特定路徑（應要求使用者明確確認或調整 allowlist）。

## 架構與資料流程設計

### 整體模組分工

此方案可分三個「責任邊界」：

- **Skill（知識與治理層）**：以 SKILL.md 定義工作流程、觸發句、注意事項、輸出格式；以 `references/` 放詳細規範與 SOP；以 `scripts/` 放可重用的小工具（例如驗證 JSON、整理 changelog）。官方建議的 skill 結構與命名規範（SKILL.md 必須精確命名、資料夾用 kebab-case、文件不放 README.md）可直接套用。citeturn11view4turn1view3  
- **MCP server（連接與執行層）**：提供檔案讀寫、索引更新、檢索、會話存取等工具；並以 MCP 的核准/權限模型確保「每次動作受控」。citeturn4view1turn4view0  
- **SQLite 索引庫（資料層）**：同一個 `.db` 檔中同時承載 FTS5（詞彙索引）與 sqlite-vec（向量索引）以及 session/audit 表，達到部署簡化與一致性交易（同一個 transaction 同步更新 metadata、FTS、vec）。FTS5 內建 `bm25()` 與 rank 配置；sqlite-vec 提供 `vec0` 虛擬表與 `MATCH` 查詢回傳 distance。citeturn13view0turn10view0

此外，若你要降低工具定義與中間結果塞滿 context 的風險，可把「大量資料處理」放在 MCP server 的程式碼端完成（例如先在本地把 100 筆候選做 rerank/聚類，再把前 10 筆摘要回傳），這與官方對「工具過多/結果過大會消耗 token」的觀察一致。citeturn18view0turn12view3

### 架構與資料流流程圖

```mermaid
flowchart LR
  U[使用者] --> C[Claude + Skill]
  C -->|tool call| M[MCP Server: vault/index/search/session]
  M --> V[Obsidian Vault (Markdown 檔案樹)]
  M --> D[(SQLite 索引庫\nFTS5 + sqlite-vec + session/audit)]
  M -->|結果(摘要/候選/引用)| C
  C -->|漸進式披露\n(概覽->展開)| U
```

```mermaid
flowchart TD
  A[檔案事件/手動觸發] --> B[去抖動與批次化]
  B --> C[讀取 Markdown + frontmatter]
  C --> D[解析/切 chunk\n保留 heading 路徑與 offset]
  D --> E[向量化\n(embedding)]
  D --> F[詞彙索引\nFTS5 upsert]
  E --> G[sqlite-vec upsert\nvec0 rowid=chunk_id]
  F --> H[transaction commit]
  G --> H
  H --> I[更新 catalog/hash/mtime]
  I --> J[寫入 audit log\n與 session delta]
```

### 與 Obsidian 的整合邊界

若你打算以 Obsidian plugin 作為 MCP server 的一部分（或 plugin 做事件轉發），需注意 Obsidian 的 Vault 概念就是一個資料夾集合；plugin 也可用 vault API 列出 Markdown 檔案並讀取內容，且官方建議的 `cachedRead()`/`read()` 選擇與「避免讀到磁碟外部變更的舊副本」有關。citeturn1view1  

若僅採「外部服務監聽 Vault 目錄」，則不依賴 Obsidian API，但需要自行處理跨平台檔案事件差異與同步工具造成的 rename/atomic write 模式。

## 混合檢索與索引更新演算法

### 索引資料模型與表格設計

建議將索引最小單位設為「chunk」而非「整份筆記」，原因是：漸進式披露天然以段落/標題區塊為單位更可控；且向量檢索在 chunk 粒度通常更準確。索引表可分四類：

- **文件層（doc）**：路徑、檔名、project_id、frontmatter、mtime、content_hash、大小。  
- **chunk 層**：doc_id、heading_path、start_offset/end_offset、chunk_text、語義摘要（可選）。  
- **FTS5 表**：以 chunk 為 row，欄位可拆為 `title/headings/body/tags/properties` 幾個欄位，方便欄位權重。FTS5 支援 external content table（content 指向另一張表），但「一致性由使用者負責」，不一致時結果不可預期，因此需嚴格用 transaction 或 triggers 維持同步。citeturn9view0turn13view0turn13view3  
- **sqlite-vec vec0 表**：以 `chunk_id` 作為 rowid，embedding 欄位如 `float[dim]`。

### BM25（FTS5）檢索要點

SQLite FTS5 內建 `bm25()`，回傳數值越小代表匹配越好；並提供明確公式、固定參數（k1=1.2、b=0.75），以及「欄位權重」：可在 `bm25(table, w1, w2, ...)` 中為各欄位指定權重，適合把標題、heading、frontmatter 核心欄位（如 project/status）提高權重。citeturn13view0  

FTS5 同時支援以 `ORDER BY rank` 做相關性排序，且文件指出使用 `rank` 可能比直接呼叫 `bm25()` 更快（尤其搭配 LIMIT/提前中止）。citeturn13view0turn13view1  

FTS5 亦支援多種 tokenizer（unicode61、porter、trigram 等）與 tokenize 參數配置；若你的 Vault 同時包含中英混雜、代碼、ID，trigram 有利於子字串匹配（但索引體積與誤召回要額外評估）。citeturn13view4

### sqlite-vec 向量檢索要點

sqlite-vec 以 `vec0` 虛擬表保存向量欄位（例如 `float[8]`），並支援以 `MATCH` 進行 KNN 查詢、回傳距離（distance），由小到大排序取得最近鄰。官方 README 的範例顯示向量可用 JSON 字串插入，查詢時同樣以 JSON 提供 query vector。citeturn10view0  

sqlite-vec 仍處 pre-v1，官方明示可能有 breaking changes；因此在生產落地上，建議固定版本、並在 schema migration 與重建策略上預留成本。citeturn1view0  

在 Python 環境，官方建議使用 `sqlite_vec.load(db)` 將 extension 載入連線，並在載入前後切換 `enable_load_extension`；且提到部分功能建議 SQLite 3.41+。這些細節對部署與可攜性非常關鍵（尤其 macOS 內建 SQLite/Python 與 extension 支援差異）。citeturn17view0

### 混合檢索演算法設計與權重調整策略

#### 基準混合公式（70/30）

因 BM25（FTS5）與向量距離（sqlite-vec）的數值尺度不同，混合前應先做「每次查詢的歸一化/校準」。推薦一個可解釋且易落地的流程：

1) 取兩路候選：
- lexical：FTS5 取 top_k_lex（例如 50），回傳 `bm25` 或 `rank`  
- vector：vec0 取 top_k_vec（例如 50），回傳 distance（越小越好）citeturn13view0turn10view0  

2) 將分數轉為「越大越好」的相似度：
- lexical：若使用的是 `bm25()`（越小越好），可用 `lex_score = -bm25`（把負值翻轉成正向越大越好），再做壓縮，例如 `lex_norm = lex_score / (lex_score + α)`（α 可取候選集的中位數）。`bm25()` 在 FTS5 之所以帶有 `-1` 項，是為了讓升冪排序得到最佳結果；因此做符號翻轉是合理的工程處理。citeturn13view0  
- vector：distance 轉相似度可用 `vec_norm = 1 / (1 + distance)`（單調遞減且有界），或用 per-query min-max。  

3) 混合：`final = 0.7 * lex_norm + 0.3 * vec_norm`。

4) 取 top_k_final（例如 10）輸出，並攜帶 `lex_norm/vec_norm/final` 以利除錯與權重調整。

#### 動態權重調整策略（建議納入 settings）

在固定 70/30 的基礎上，建議提供三種「可控的動態調整」：

- **查詢型態觸發**：  
  - 若 query 像「精確詞」或含代碼/ID（例如 `PRJ-123`、`#tag`、`path:`、引號短語），提高 BM25 權重（例如 0.85/0.15）。  
  - 若 query 為自然語言問題、或包含多句描述（需求、背景、限制），提高向量權重（例如 0.6/0.4）。  
- **詞彙命中可信度**：若 lexical top1 與 top10 的分數差距非常小（代表詞彙訊號弱或語料過密），提高向量權重；反之降低。  
- **候選一致性檢查**：若 vector 與 lexical 的候選重疊度高（例如 Jaccard > 0.3），維持 70/30；若重疊度極低，視為「語義與詞彙訊號衝突」，可改採更保守的融合（例如 Reciprocal Rank Fusion 變體）並回報「不確定性」。

此策略的工程理由是：詞彙檢索對「明確關鍵詞」有強優勢；語義向量對「同義改寫、隱含描述」有補強；在專案級 Vault 裡，兩者訊號強弱會隨查詢而變。FTS5 提供欄位權重與 rank 設定，使詞彙路徑的可控性很高；sqlite-vec 則提供距離與 KNN 作為語義路徑的穩定基礎。citeturn13view0turn10view0

### 索引建立、重建與一致性

FTS5 官方提供 `rebuild` 指令，可在內容表與索引不一致時丟棄並重建整個索引；這對頻繁更新或跨裝置同步（偶發錯位）很有價值。citeturn13view3  

設計上建議預留兩條路徑：

- **增量更新**：單檔案變更 → 只重切該檔 chunks → 更新 chunks 表 + FTS row + vec row（同一 transaction）。  
- **重建策略**：當檢測到大量不一致（例如連續 N 次查詢命中不存在的 rowid）、或 schema 版本升級、或 sqlite-vec/FTS tokenizer 變更時，觸發全量 rebuild（含向量重算）。

## Obsidian 檔案治理與漸進式披露

### Vault 目錄結構與命名規範建議

以下提供一套偏「專案級資料庫」的 Vault 建議結構，重點是：路徑本身可提供語義（project/area/resource），並能映射到索引分區與更新頻率（讓索引器可用不同策略處理）。此為建議而非硬性；真正落地應以你現有 Vault 習慣為準。

- `00-inbox/`：臨時收集，更新頻率高，允許較鬆的命名，索引採「快」優先（短去抖動、允許稍後補全 metadata）。  
- `10-projects/<project-slug>/`：每個專案一資料夾，包含 `_index.md`（專案主檔）、`notes/`、`meetings/`、`decisions/`、`tasks/` 等子層。  
- `20-areas/`：長期領域（非專案），更新中等。  
- `30-resources/`：資料庫/素材庫（讀多寫少），可較重的向量化（例如較大 chunk、較多摘要欄位）。  
- `90-archive/`：封存（幾乎不更新），索引可凍結或低頻重算。  

命名上建議引入兩種穩：  
1) **穩定識別**：`id`（frontmatter），用 UUID 或短碼；用於 rename 不破壞引用與索引。  
2) **人類可讀**：檔名以自然語言為主，但避免頻繁更名；需要更名時以 `id` 保持追蹤。

### 漸進式披露策略與讀取/載入機制

你提出的「避免一次塞滿 context」可在兩個層級實現：

- **Skill 層的漸進式披露**：官方明確描述 Skills 由三層構成（frontmatter 永遠載入、SKILL.md 主體按需載入、其他連結檔案再按需載入），並指出大上下文會拖慢或降低品質，解法包括把詳細文件移到 `references/`、以連結替代內嵌、SKILL.md 控制在一定大小（例如 < 5,000 words），以及避免同時啟用過多 skills。citeturn11view0turn12view3  
- **檢索回應層的漸進式披露**：檢索結果先回「短清單 + 每筆 1–2 行摘要 + 片段引用」，只在使用者要求時才取回完整 chunk 或整份檔案。這能把工具結果 token 成本與模型上下文壓力限制在可控範圍，符合官方對「工具定義/工具結果膨脹會消耗 token」的警示。citeturn18view0  

若你採 Obsidian plugin 讀檔，官方建議 `cachedRead()` 適合只顯示內容、避免重複讀磁碟；而 `read()` 適合要讀取後修改寫回，降低覆寫「剛在 app 外被改過」的舊副本風險。citeturn1view1

### 路徑檔案結構映射範例表

下表提供一個「路徑→用途→Agent 功能→更新頻率」的範例映射，你可把它落地成 `references/path_map.md` 與索引器的設定檔（例如 `path_map.yaml`），並由 `vault.scan` 工具輸出/校驗。

| 範例路徑 | 用途 | 對應 Agent 功能 | 更新頻率建議 |
|---|---|---|---|
| `00-inbox/` | 收集、未歸檔筆記 | 快速索引、去重、提議歸檔路徑、補 frontmatter | 高（秒～分鐘級） |
| `10-projects/alpha/_index.md` | 專案主頁（目標、範圍、里程碑） | 專案摘要、狀態快照、關鍵決策索引 | 中（天級） |
| `10-projects/alpha/meetings/2026-02-10.md` | 會議紀錄 | 萃取 action items、連結任務、生成決策紀錄 | 中高（會後立即） |
| `10-projects/alpha/decisions/ADR-0003.md` | 決策紀錄（ADR） | 決策查詢、影響分析、變更追蹤 | 低～中 |
| `10-projects/alpha/tasks/` | 任務拆解與追蹤 | 任務彙總、依 status 聚合、週報生成 | 高 |
| `20-areas/security/` | 長期領域知識 | 維護知識卡、概念圖、FAQ | 中 |
| `30-resources/papers/` | 參考資料庫 | 摘要、引用、主題聚類（向量權重可提高） | 低 |
| `90-archive/alpha/` | 封存專案 | 只讀檢索、低頻重建索引 | 很低 |
| `.projecthub/index.db`（自訂） | 本地索引資料庫 | FTS5/sqlite-vec/session/audit 的持久化存放 | 每次更新 |
| `.projecthub/audit/CHANGELOG.md`（自訂） | 變更與審計 | 人類可讀的變更摘要、可追溯引用 | 每次寫操作 |

## 會話、版本與變更管理

### 會話自動保存與壓縮規則

建議把「會話」視為一個可持久化狀態機（而不只是一串對話文字），保存內容至少包含：

- `session_id`、關聯 `project_id(s)`  
- 重要決策與假設（決策日誌）  
- 最近的檢索足跡（最近查過哪些筆記/哪些 chunk）  
- 待辦清單（agent 內部的 next action queue）  
- rolling summary（壓縮後的上下文）

在設計理念上，官方也指出「工具環境 + 檔案系統存取」可用於狀態持久化：把中間結果寫入檔案，後續再讀回續做。citeturn18view0

可落地的自動規則（範例）：

- **自動保存（save）觸發**：  
  - 每次工具呼叫後（尤其是 `doc.apply_patch` / `index.update`）  
  - 或每累積 N 個 turn（例如 10）  
  - 或距離上次 save 超過 T 分鐘（例如 5 分鐘）

- **自動壓縮（compact）觸發**：  
  - 估算 token > 門檻（例如 20k）  
  - 或 `session_events` 超過門檻（例如 100 條）  
  - 或切換專案（project context switch）時

壓縮應採「可追溯」格式：summary 每一段都帶上它來源的（doc_path, chunk_id）清單，確保之後需要還原時能回抓原文，不把關鍵上下文永久丟失。

### 手動整理指令範例（Skill 可規範的 UX）

以下是適合寫進 SKILL.md 的「使用者可下達的整理命令」範例（你可用 slash 指令或固定句式；重點是可測、可追蹤）：

- `/session.save`：立即落盤 session state（回傳 session_version）。  
- `/session.compact policy=balanced`：產生 rolling summary，並列出被保留的「事實、決策、未決項、引用來源」。  
- `/session.diff since=last_save`：列出自上次保存以來做過的工具呼叫與檔案變更。  
- `/project.snapshot alpha`：輸出專案快照（目標、進度、關鍵風險、下一步），但只引用 top N chunks。  
- `/log.show last=20`：顯示最近 20 筆 audit log（含 hash）。  

### 版本/變更紀錄格式（建議 Markdown + JSON 雙軌）

為兼顧「人類可讀」與「機器可驗證」，建議同時維護：

1) `CHANGELOG.md`（人類可讀，適合在 Vault 內）  
2) `audit_log`（SQLite table，適合做查詢與一致性驗證）

`CHANGELOG.md` 單筆紀錄建議格式（範例欄位）：
- timestamp（ISO 8601）
- actor（user / agent）
- action（create/update/rename/delete/index）
- target_path
- expected_hash / new_hash
- reason（1–3 句）
- references（doc_id/chunk_id list）
- rollback_hint（可選）

### 衝突解決建議（含頻繁更新情境）

衝突主要來自三類：

- **寫入前內容已變**：用 `expected_hash` 檢測；不符則拒絕寫入、要求使用者選擇「重新讀取後重做」「三方合併」「放棄」。  
- **rename/同步造成的 path 漂移**：以 doc_id（frontmatter）為主鍵追蹤，path 只是屬性；rename 只更新 path，不重建 doc identity。  
- **索引更新與查詢競爭造成的 `SQLITE_BUSY`**：寫入序列化、短交易、重試退避；必要時暫停增量更新、讓查詢走「上一版快照」索引。WAL 有助於讀寫並行，但仍要準備少數 `SQLITE_BUSY` 邊界案例。citeturn19view0turn19view1

## 實作範例與測試驗收

### 關鍵程式碼片段（Python 範例）

以下示例聚焦於你要求的幾個關鍵點：MD 解析、向量化存入 sqlite-vec、BM25（FTS5）檢索整合、混合排序、以及漸進式披露的回應組裝。請視實際 embedding 模型/服務替換 `embed_texts()`。

```python
import os
import re
import json
import time
import hashlib
import sqlite3
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional

import frontmatter  # pip install python-frontmatter
import sqlite_vec   # pip install sqlite-vec


# -------------------------
# Markdown parsing & chunking
# -------------------------

HEADING_RE = re.compile(r"^(#{1,6})\s+(.*)\s*$")

@dataclass
class Chunk:
    chunk_id: int
    doc_path: str
    heading_path: str
    start_line: int
    end_line: int
    text: str


def sha256_text(s: str) -> str:
    return hashlib.sha256(s.encode("utf-8")).hexdigest()


def parse_markdown(md_text: str) -> Tuple[Dict, str]:
    """
    Returns: (frontmatter_dict, markdown_body)
    """
    post = frontmatter.loads(md_text)
    return dict(post.metadata or {}), post.content or ""


def chunk_by_headings(doc_path: str, md_body: str, base_chunk_id: int) -> List[Chunk]:
    """
    Simple heading-based chunker:
    - Each top-level segment (between headings) becomes a chunk.
    - heading_path keeps a breadcrumb like "H1 Title / H2 Subtitle".
    """
    lines = md_body.splitlines()
    headings_stack: List[Tuple[int, str]] = []
    chunks: List[Chunk] = []

    seg_start = 0
    seg_heading_path = ""

    def current_heading_path() -> str:
        return " / ".join([t for _, t in headings_stack])

    def flush_segment(seg_end: int, chunk_id: int):
        nonlocal seg_start, seg_heading_path
        text = "\n".join(lines[seg_start:seg_end]).strip()
        if text:
            chunks.append(
                Chunk(
                    chunk_id=chunk_id,
                    doc_path=doc_path,
                    heading_path=seg_heading_path,
                    start_line=seg_start + 1,
                    end_line=seg_end,
                    text=text,
                )
            )

    next_chunk_id = base_chunk_id
    seg_heading_path = ""  # before first heading

    for i, line in enumerate(lines):
        m = HEADING_RE.match(line)
        if m:
            # flush previous segment up to heading line
            flush_segment(i, next_chunk_id)
            next_chunk_id += 1

            level = len(m.group(1))
            title = m.group(2).strip()

            # update heading stack
            while headings_stack and headings_stack[-1][0] >= level:
                headings_stack.pop()
            headings_stack.append((level, title))

            seg_start = i  # include the heading line in the chunk
            seg_heading_path = current_heading_path()

    # final segment
    flush_segment(len(lines), next_chunk_id)
    return chunks


# -------------------------
# SQLite schema
# -------------------------

SCHEMA_SQL = """
PRAGMA journal_mode=WAL;

CREATE TABLE IF NOT EXISTS docs (
  doc_id INTEGER PRIMARY KEY,
  doc_path TEXT NOT NULL UNIQUE,
  project_id TEXT,
  title TEXT,
  mtime_ns INTEGER,
  content_hash TEXT,
  frontmatter_json TEXT
);

CREATE TABLE IF NOT EXISTS chunks (
  chunk_id INTEGER PRIMARY KEY,
  doc_id INTEGER NOT NULL,
  heading_path TEXT,
  start_line INTEGER,
  end_line INTEGER,
  text TEXT NOT NULL,
  text_hash TEXT NOT NULL,
  FOREIGN KEY(doc_id) REFERENCES docs(doc_id) ON DELETE CASCADE
);

-- FTS5 index over chunks; separate columns allow different weights
CREATE VIRTUAL TABLE IF NOT EXISTS chunks_fts USING fts5(
  title,
  heading_path,
  text,
  tags,
  content='',
  tokenize='unicode61'
);

-- sqlite-vec vector table; embedding dim must match your model
-- rowid will be chunk_id for easy joins
CREATE VIRTUAL TABLE IF NOT EXISTS chunks_vec USING vec0(
  embedding float[768]
);

CREATE INDEX IF NOT EXISTS idx_chunks_doc_id ON chunks(doc_id);
"""

def open_db(db_path: str) -> sqlite3.Connection:
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row

    # Load sqlite-vec extension (Python official usage)
    conn.enable_load_extension(True)
    sqlite_vec.load(conn)
    conn.enable_load_extension(False)

    conn.executescript(SCHEMA_SQL)
    return conn


# -------------------------
# Embedding stub (replace with your model/service)
# -------------------------

def embed_texts(texts: List[str]) -> List[List[float]]:
    """
    Return embeddings as list of float vectors.
    Replace with:
    - local sentence-transformers
    - remote embedding API
    """
    # Dummy: do not use in production
    return [[0.0] * 768 for _ in texts]


# -------------------------
# Upsert document & indexes
# -------------------------

def upsert_document(conn: sqlite3.Connection, doc_path: str, md_text: str):
    meta, body = parse_markdown(md_text)
    title = meta.get("title") or os.path.splitext(os.path.basename(doc_path))[0]
    project_id = meta.get("project") or meta.get("project_id")

    mtime_ns = int(time.time_ns())
    content_hash = sha256_text(md_text)
    frontmatter_json = json.dumps(meta, ensure_ascii=False)

    with conn:  # transaction
        # docs row
        conn.execute("""
          INSERT INTO docs(doc_path, project_id, title, mtime_ns, content_hash, frontmatter_json)
          VALUES(?,?,?,?,?,?)
          ON CONFLICT(doc_path) DO UPDATE SET
            project_id=excluded.project_id,
            title=excluded.title,
            mtime_ns=excluded.mtime_ns,
            content_hash=excluded.content_hash,
            frontmatter_json=excluded.frontmatter_json
        """, (doc_path, project_id, title, mtime_ns, content_hash, frontmatter_json))

        doc_id = conn.execute("SELECT doc_id FROM docs WHERE doc_path=?", (doc_path,)).fetchone()["doc_id"]

        # delete old chunks & vector/fts rows (simple strategy; optimize later by diffing)
        old_chunk_ids = [r["chunk_id"] for r in conn.execute("SELECT chunk_id FROM chunks WHERE doc_id=?", (doc_id,))]
        for cid in old_chunk_ids:
            conn.execute("DELETE FROM chunks_vec WHERE rowid=?", (cid,))
        conn.execute("DELETE FROM chunks WHERE doc_id=?", (doc_id,))
        conn.execute("DELETE FROM chunks_fts WHERE rowid IN (%s)" % ",".join(["?"] * len(old_chunk_ids)), old_chunk_ids) if old_chunk_ids else None

        # insert new chunks
        base_chunk_id = int(time.time() * 1000)  # example: monotonic-ish
        chunks = chunk_by_headings(doc_path, body, base_chunk_id)

        embeddings = embed_texts([c.text for c in chunks])

        for c, emb in zip(chunks, embeddings):
            # store chunk
            conn.execute("""
              INSERT INTO chunks(chunk_id, doc_id, heading_path, start_line, end_line, text, text_hash)
              VALUES(?,?,?,?,?,?,?)
            """, (c.chunk_id, doc_id, c.heading_path, c.start_line, c.end_line, c.text, sha256_text(c.text)))

            # store FTS row (contentless FTS: we insert explicitly)
            tags = ",".join(meta.get("tags", [])) if isinstance(meta.get("tags"), list) else (meta.get("tags") or "")
            conn.execute("""
              INSERT INTO chunks_fts(rowid, title, heading_path, text, tags)
              VALUES(?,?,?,?,?)
            """, (c.chunk_id, title, c.heading_path, c.text, tags))

            # store vector row; sqlite-vec accepts JSON string or binary
            conn.execute("""
              INSERT INTO chunks_vec(rowid, embedding)
              VALUES(?, ?)
            """, (c.chunk_id, json.dumps(emb)))


# -------------------------
# Retrieval: BM25 + sqlite-vec
# -------------------------

def search_lexical(conn: sqlite3.Connection, query: str, top_k: int = 50) -> Dict[int, float]:
    """
    Return: {chunk_id: lex_score} where higher is better after transform.
    Use bm25(column weights) to boost title/headings over body/tags.
    """
    # FTS5 bm25(): better matches are numerically smaller, so we negate it to make higher=better
    rows = conn.execute("""
      SELECT rowid AS chunk_id, bm25(chunks_fts, 8.0, 4.0, 1.0, 2.0) AS bm25_score
      FROM chunks_fts
      WHERE chunks_fts MATCH ?
      ORDER BY bm25_score
      LIMIT ?
    """, (query, top_k)).fetchall()

    out = {}
    for r in rows:
        bm25_score = float(r["bm25_score"])
        out[int(r["chunk_id"])] = -bm25_score
    return out


def search_vector(conn: sqlite3.Connection, query_vec: List[float], top_k: int = 50) -> Dict[int, float]:
    """
    Return: {chunk_id: vec_score} where higher is better.
    sqlite-vec returns distance; we map to similarity via 1/(1+dist).
    """
    rows = conn.execute("""
      SELECT rowid AS chunk_id, distance
      FROM chunks_vec
      WHERE embedding MATCH ?
      ORDER BY distance
      LIMIT ?
    """, (json.dumps(query_vec), top_k)).fetchall()

    out = {}
    for r in rows:
        dist = float(r["distance"])
        out[int(r["chunk_id"])] = 1.0 / (1.0 + dist)
    return out


def hybrid_rank(lex: Dict[int, float], vec: Dict[int, float], w_lex: float = 0.7, w_vec: float = 0.3) -> List[Tuple[int, float, float, float]]:
    """
    Returns list of (chunk_id, final, lex_norm, vec_norm), sorted desc by final.
    Simple per-query normalization: divide by max.
    """
    ids = set(lex.keys()) | set(vec.keys())
    if not ids:
        return []

    max_lex = max(lex.values()) if lex else 1.0
    max_vec = max(vec.values()) if vec else 1.0

    ranked = []
    for cid in ids:
        lex_norm = (lex.get(cid, 0.0) / max_lex) if max_lex > 0 else 0.0
        vec_norm = (vec.get(cid, 0.0) / max_vec) if max_vec > 0 else 0.0
        final = w_lex * lex_norm + w_vec * vec_norm
        ranked.append((cid, final, lex_norm, vec_norm))

    ranked.sort(key=lambda x: x[1], reverse=True)
    return ranked


# -------------------------
# Progressive disclosure rendering
# -------------------------

def render_results_overview(conn: sqlite3.Connection, ranked: List[Tuple[int, float, float, float]], top_k: int = 10) -> str:
    """
    Return a compact overview (no full chunks), suitable for first response.
    """
    top = ranked[:top_k]
    if not top:
        return "找不到匹配結果。建議：調整關鍵字、改用更具體的專案/標籤 filter，或先執行 index.build。"

    # Fetch minimal metadata (doc_path, heading_path, line range)
    placeholders = ",".join(["?"] * len(top))
    rows = conn.execute(f"""
      SELECT c.chunk_id, d.doc_path, d.title, c.heading_path, c.start_line, c.end_line
      FROM chunks c
      JOIN docs d ON d.doc_id=c.doc_id
      WHERE c.chunk_id IN ({placeholders})
    """, [cid for cid, *_ in top]).fetchall()

    meta_by_id = {int(r["chunk_id"]): r for r in rows}

    lines = ["候選結果（概覽，需展開時請指定序號或 chunk_id）："]
    for i, (cid, final, lex_n, vec_n) in enumerate(top, start=1):
        m = meta_by_id.get(cid)
        if not m:
            continue
        lines.append(
            f"{i}. {m['title']} | {m['doc_path']} | {m['heading_path']} "
            f"(L{m['start_line']}-L{m['end_line']}) | score={final:.3f} (lex={lex_n:.3f}, vec={vec_n:.3f}) | chunk_id={cid}"
        )
    return "\n".join(lines)


def expand_chunk(conn: sqlite3.Connection, chunk_id: int, max_chars: int = 1200) -> str:
    """
    Second-level disclosure: return chunk text (truncated).
    """
    r = conn.execute("""
      SELECT d.doc_path, d.title, c.heading_path, c.start_line, c.end_line, c.text
      FROM chunks c JOIN docs d ON d.doc_id=c.doc_id
      WHERE c.chunk_id=?
    """, (chunk_id,)).fetchone()
    if not r:
        return "chunk 不存在或已被更新。請重新檢索。"

    text = r["text"]
    if len(text) > max_chars:
        text = text[:max_chars] + "\n...[truncated]..."
    return (
        f"來源：{r['title']} | {r['doc_path']} | {r['heading_path']} (L{r['start_line']}-L{r['end_line']})\n\n"
        f"{text}"
    )
```

實作注意事項（與官方文件關聯最強的部分）：

- sqlite-vec 的 Python 用法與 extension loading 開關，官方示例為 `sqlite_vec.load(db)` 並搭配 `enable_load_extension(True/False)`；此點影響跨平台可用性與安全策略（後述）。citeturn17view0turn16view3  
- FTS5 的 `bm25()` 支援欄位權重，且其回傳值設計為「越小越好」，並解釋了 `-1` 項與排序陷阱；程式中用 `-bm25` 翻成「越大越好」以便混合。citeturn13view0  
- sqlite-vec 的 SQL 介面以 `MATCH` 查詢與 `ORDER BY distance` 得到最近鄰，與官方 README 範例一致。citeturn10view0  

### 測試計畫與驗收指標

#### 測試資料設計

為了驗證 70/30 混合的有效性，建議建立一個「查詢集」與「標註集」：

- 查詢集：至少 100 條，分為（精確關鍵字/ID/路徑導向）與（自然語言問句/摘要導向）兩類。  
- 標註集：每條查詢標註 top-5 相關 chunks（或文件），可用三段式相關性（0/1/2）以支援 nDCG。  
- 更新壓力集：模擬 1 分鐘內 200 次 modify（例如同步工具造成的批次重寫），觀察增量索引延遲與錯誤率。

#### 指標與門檻（範例）

Skill 端的測試與驗收，官方提供了可操作的指標例子，例如：技能在 90% 相關問題上能觸發、workflow 在 X 次工具呼叫內完成、每 workflow 0 次失敗 API 呼叫等；你可以把它轉成自家驗收門檻（例如在 staging 跑 20 條測試 prompt）。citeturn3view1  

本系統建議的驗收指標（可分「檢索品質」「效率」「資源」「可靠性」）：

| 分類 | 指標 | 建議門檻（起始） | 備註 |
|---|---|---:|---|
| 檢索品質 | Recall@10（chunk） | ≥ 0.85 | 以標註集計算 |
| 檢索品質 | MRR@10 | ≥ 0.60 | 對「找對第一個」更敏感 |
| 檢索品質 | nDCG@10 | ≥ 0.70 | 支援多層相關性 |
| 延遲 | p95 查詢延遲 | ≤ 400ms（本機） | 分拆 lexical/vec/merge |
| 更新 | p95 增量索引延遲 | ≤ 2s（高頻資料夾） | 含去抖動 |
| 錯誤 | `SQLITE_BUSY` 未處理失敗率 | 0 | 必須被重試/排隊吸收 citeturn19view0 |
| 資源 | 索引 DB 成長率 | 可預期/可壓縮 | 定期 vacuum/checkpoint（策略依實作） |

## 部署與運維

### Skill 打包與分層披露落地

官方技能文件清楚規定：skill 以資料夾形式存在，`SKILL.md` 必須精確命名、資料夾用 kebab-case、並把可選資源放進 `scripts/`、`references/`、`assets/`；此外 YAML frontmatter 是決定是否載入 skill 的關鍵，description 應同時包含「做什麼」與「何時用」（trigger conditions），並避免不允許的字元與保留命名。citeturn11view4turn11view5turn12view1  

同一份官方指引也指出「Large context issues」會造成 skill 變慢或品質下降，解法包括把詳細內容移到 `references/`、以連結替代內嵌、控制 SKILL.md 大小、以及避免同時啟用過多 skills。你提出的漸進式披露需求，應以此作為硬性設計原則，而非事後補救。citeturn12view3turn11view0

### MCP server 部署與更新

若你的目標使用情境包含 Claude Desktop，本地 MCP server 是自然選擇；官方教學指出 MCP server 能提供對本地資源的受控存取，並強調工具動作需要使用者明確核准。citeturn4view1  

若要降低安裝門檻，可考慮把 MCP server 打包成 Desktop Extensions；官方工程文章提到其目的在於把安裝從「手動改 JSON、處理相依」變成「一鍵安裝」，並且檔案副檔名改為 `.mcpb`（命名慣例更新）。citeturn4view2  

### SQLite 併發、WAL 與鎖定策略（運維面）

SQLite 官方指出 WAL 能帶來較高併發：讀者不阻擋寫者、（多數情況）寫者也不阻擋讀者；同時也提醒 WAL 模式仍會在特定場景回報 `SQLITE_BUSY`，例如資料庫關閉清理 WAL、或 recovery 時需要獨占鎖。citeturn19view0  

SQLite 也明確說明：交易隔離預設為 serializable，並以「序列化寫入」達成，因此同時間只有單一寫者；這意味著你必須把「索引寫入」集中在一條寫入佇列上，避免多執行緒/多進程同時寫相同 DB。citeturn19view1  

在非 WAL（rollback mode）下，寫入會把讀者暫時趕出以取得獨占；在 WAL 下可讀寫並行，但仍要處理鎖與忙碌狀態。鎖定模型細節可參考官方 locking 文件。citeturn19view2

### 安全性與存取控制（本地/遠端、憑證、加密、敏感資訊）

#### MCP 與工具安全

MCP 官方安全最佳實務文件將風險拆成多類（如 confused deputy、SSRF、session hijacking、local MCP server compromise），並強調 scope minimization 等緩解策略；這表示你的 MCP server 必須內建：路徑 allowlist、最小權限工具拆分（read vs write）、輸入驗證、審計紀錄與速率限制。citeturn16view0  

Claude Code 的官方安全文件亦明確提醒：只使用你信任的 MCP servers、可設定 MCP permissions，且 Anthropic 不管理或審核第三方 MCP server；因此企業/團隊落地務必把 MCP server 視為受管軟體資產（版本控管、簽章、審計）。citeturn16view1  

#### SQLite extension loading 的安全風險與做法

sqlite-vec 屬 loadable extension，SQLite 官方文件指出 extension loading 為安全理由預設關閉；若要啟用，需以 C-API（`sqlite3_db_config(...ENABLE_LOAD_EXTENSION...)`）或相關介面開啟。citeturn16view3  

更重要的是 SQLite 的 API 參考明確給出安全警告：建議用 `SQLITE_DBCONFIG_ENABLE_LOAD_EXTENSION` 讓「只開 C-API、不開 SQL `load_extension()`」成為可能，避免 SQL injection 進一步獲得載入 extension 的能力。這意味著你的 MCP server 應在初始化階段以最小暴露方式載入 sqlite-vec，而不允許任意 SQL 字串被執行。citeturn16view2turn16view3  

#### 資料加密與敏感資訊處理

SQLite 本體不內建通用透明加密時，常見做法是採加密擴充或改版；SQLite 官方提供 SEE（SQLite Encryption Extension），可使資料庫內容（含 metadata）以加密形式儲存，並說明其授權屬商業授權。citeturn16view4  

若你偏好開源/跨平台生態，也可考慮 SQLCipher（由 entity["company","Zetetic","sqlcipher vendor"] 維護），它基於 SQLite 並以 PRAGMA 等方式提供加密相關擴充（仍需注意授權與相容性）。citeturn16view5  

敏感資訊處理的工程建議（需寫入 SKILL.md 的“安全守則”）：
- 不把 API key/token 寫進 Vault；改用 OS keychain 或環境變數注入 MCP server。  
- 任何寫回 Vault 的動作必須：① 先顯示 diff 摘要、② 做 expected_hash 比對、③ 寫入 audit log。  
- 若允許遠端存取（例如遠端 DB 或遠端 Vault），必須加上 mTLS 或 OAuth2，並把 token scope 限制到最小（參考 MCP 安全文件中對授權/代理風險的提醒）。citeturn16view0turn16view1  

### 備份、監控、日誌、升級流程

- **備份**：  
  - 索引 DB：每日快照 + 寫操作前的 transaction-level 變更紀錄（可快速重建），以及每次 schema 變更前的完整備份。  
  - Vault：推薦搭配版本控制或同步工具，但需制定「索引以 Vault 為準」的權威來源。  
- **監控**：  
  - 查詢延遲（p50/p95/p99）、增量更新延遲、`SQLITE_BUSY` 次數、embedding 失敗率。  
- **日誌**：  
  - MCP server：結構化日誌（json）、涵蓋 tool name、耗時、輸入大小、輸出大小、錯誤碼。  
  - Audit log：可稽核（含 hash、path、actor、timestamp）。  
- **升級**：  
  - sqlite-vec 因 pre-v1 可能破壞性更新，升級必須先跑 staging 的全量重建與檢索回歸測試，再推到正式；必要時以 feature flag 切換新舊 vec table。citeturn1view0  

### 待確認項目

1) 你預期的 Vault 規模（Markdown 檔案數、總字數、附件規模）與「高頻更新」的定義（例如每分鐘 modify 次數、是否來自同步工具批次更新）是什麼？這會直接影響 chunk 策略、批次更新大小、以及 WAL/寫入佇列設計。citeturn19view0turn19view1  
2) embedding 的限制：你希望**完全離線**（本地模型）還是可用遠端 API？若可用遠端，是否有資料外送限制（PII/機密）？  
3) 你偏好的部署介面：以 Claude Desktop 為主（本地 MCP server），或以 Claude API 為主（自建 MCP client + service）？兩者在工具核准、權限及安裝體驗上不同。citeturn4view1turn1view2turn4view2  
4) Vault 的「寫回政策」：系統是否允許自動修改筆記（補 frontmatter、整理標題、歸檔搬移），還是僅允許提出建議並由人確認？這影響權限模型與衝突處理設計。  
5) BM25 欄位權重：你是否已有既定欄位（例如 `type/status/owner/sprint`）與其重要性排序？FTS5 支援欄位權重，但需要你給出欄位語義與權重初始值。citeturn13view0  
6) 索引 DB 的安全等級：需不需要「加密 at rest」？若需要，偏好 SQLite SEE（商業授權）或 SQLCipher（生態廣、但仍需授權/整合評估）？citeturn16view4turn16view5  
7) 你希望「會話保存」落在 Vault（讓它可同步/可檢視）還是落在索引 DB（較結構化、較難被同步工具干擾）？或兩者並行？